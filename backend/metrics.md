# Interview Metrics & Logging\n\nThis document describes the core metrics that are emitted by the backend to\n`metrics.log` for offline analysis of interview quality and multimodal\nbehaviour.\n\n## Log file\n\n- Default path: `metrics.log` (relative to the backend working directory)\n- Format: one JSON object per line (newline-delimited JSON)\n- Top-level fields:\n  - `ts`: ISO-8601 UTC timestamp when the row was written\n  - `type`: one of `session_report` or `media_report`\n  - `user_id`: optional user identifier (may be null)\n  - `session_id`: interview session identifier\n\n## Session report metrics (`type = \"session_report\"`)\n\nEmitted when `/interview/sessions/{id}/report` generates an\n`InterviewEvaluation` for a session.\n\nStructure (simplified):\n\n```jsonc\n{\n  "ts": "...",\n  "type": "session_report",\n  "user_id": "...",\n  "session_id": "...",\n  "evaluation": {\n    "session_id": "...",\n    "overall_score": 78.5,\n    "score": 78.5,\n    "dimensions": [\n      { "name": "结构化表达（STAR）", "score": 76.0, "comment": "..." },\n      { "name": "表达清晰度", "score": 82.0, "comment": "..." },\n      { "name": "反思与成长意识", "score": 70.0, "comment": "..." }\n    ],\n    "strength_tags": ["表达清晰度"],\n    "risk_tags": ["反思与成长意识"],\n    "suggested_next_tasks": [\n      { "type": "practice_session", "focus": "结构化表达（STAR）", "suggested_duration_min": 20 }\n    ]\n  },\n  "diagnostics": {\n    "total_words": 520,\n    "avg_answer_len": 130.0,\n    "filler_ratio": 0.025,\n    "reflection_score": 55.0\n  }\n}\n```\n\nNotes:\n\n- The long free-form `feedback` text from `InterviewEvaluation` is **not**\n  included in `evaluation` to keep the log compact.\n- `diagnostics` contains lightweight text-only statistics that are useful for\n  calibrating heuristic scoring rules (e.g. thresholds for filler words or\n  average answer length).\n\n## Media report metrics (`type = \"media_report\"`)\n\nEmitted when `/interview/media/{id}/report` generates a `MediaEvaluation` for\n  a single audio or video recording.\n\nStructure (simplified):\n\n```jsonc\n{\n  "ts": "...",\n  "type": "media_report",\n  "user_id": "...",\n  "session_id": "...",\n  "media_id": "...",\n  "media_type": "audio",\n  "audio_features": {\n    "speech_rate": 155.0,\n    "pause_ratio": 0.18,\n    "filler_word_ratio": 0.03,\n    "pitch_variance": 0.12,\n    "emotion": "neutral"\n  },\n  "video_features": {\n    "eye_contact_score": 0.68,\n    "smile_ratio": 0.22,\n    "posture_score": 0.7,\n    "head_movement_score": 0.3,\n    "dominant_emotion": "neutral"\n  }\n}\n```\n\nNotes:\n\n- `audio_features` and `video_features` are directly derived from the\n  corresponding Pydantic models in `app.models.schemas` (fields are optional\n  and may be missing).\n- These metrics are intended to be joined with session-level dimensions in\n  offline analysis to study relationships such as:\n  - speech_rate vs. 表达清晰度\n  - filler_word_ratio vs. 结构化表达（STAR） score\n  - eye_contact_score vs. 面试结果等。\n\n## Suggested analysis directions\n\nWith `metrics.log` and the example notebook `backend/notebooks/ability_analysis.ipynb`,\nyou can start to answer questions such as:\n\n- 哪些能力维度的评分分布合理、区分度好？哪些维度过于集中或偏玄学？\n- 多模态特征（语速、口头禅比例、眼神接触等）的分布与维度得分是否匹配当前设定的阈值？\n- 某位学生在 3–5 场面试后，在哪些维度上有明显提升。\n\n在收集到足够的数据后，可以基于这些分布和相关性，微调后端中的启发式打分规则，\n而无需改变对外接口结构。\n
